{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "296d8e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "897e7ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"datasets/Deep_Learning_task_train_dataset.csv\", sep=',')\n",
    "train = df\n",
    "test_df = pd.read_csv(\"datasets/Deep_Learning_task_test_dataset.csv\", sep=',')\n",
    "test = test_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbc98e5",
   "metadata": {},
   "source": [
    "## Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19643b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Identifier</th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FDA15</td>\n",
       "      <td>9.30</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>249.8092</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>3735.1380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DRC01</td>\n",
       "      <td>5.92</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.019278</td>\n",
       "      <td>Soft Drinks</td>\n",
       "      <td>48.2692</td>\n",
       "      <td>OUT018</td>\n",
       "      <td>2009</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type2</td>\n",
       "      <td>443.4228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FDN15</td>\n",
       "      <td>17.50</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>Meat</td>\n",
       "      <td>141.6180</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>2097.2700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FDX07</td>\n",
       "      <td>19.20</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Fruits and Vegetables</td>\n",
       "      <td>182.0950</td>\n",
       "      <td>OUT010</td>\n",
       "      <td>1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Grocery Store</td>\n",
       "      <td>732.3800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCD19</td>\n",
       "      <td>8.93</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Household</td>\n",
       "      <td>53.8614</td>\n",
       "      <td>OUT013</td>\n",
       "      <td>1987</td>\n",
       "      <td>High</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>994.7052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Item_Identifier  Item_Weight Item_Fat_Content  Item_Visibility  \\\n",
       "0           FDA15         9.30          Low Fat         0.016047   \n",
       "1           DRC01         5.92          Regular         0.019278   \n",
       "2           FDN15        17.50          Low Fat         0.016760   \n",
       "3           FDX07        19.20          Regular         0.000000   \n",
       "4           NCD19         8.93          Low Fat         0.000000   \n",
       "\n",
       "               Item_Type  Item_MRP Outlet_Identifier  \\\n",
       "0                  Dairy  249.8092            OUT049   \n",
       "1            Soft Drinks   48.2692            OUT018   \n",
       "2                   Meat  141.6180            OUT049   \n",
       "3  Fruits and Vegetables  182.0950            OUT010   \n",
       "4              Household   53.8614            OUT013   \n",
       "\n",
       "   Outlet_Establishment_Year Outlet_Size Outlet_Location_Type  \\\n",
       "0                       1999      Medium               Tier 1   \n",
       "1                       2009      Medium               Tier 3   \n",
       "2                       1999      Medium               Tier 1   \n",
       "3                       1998         NaN               Tier 3   \n",
       "4                       1987        High               Tier 3   \n",
       "\n",
       "         Outlet_Type  Item_Outlet_Sales  \n",
       "0  Supermarket Type1          3735.1380  \n",
       "1  Supermarket Type2           443.4228  \n",
       "2  Supermarket Type1          2097.2700  \n",
       "3      Grocery Store           732.3800  \n",
       "4  Supermarket Type1           994.7052  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a0176f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Identifier</th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NCF31</td>\n",
       "      <td>9.130</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.051928</td>\n",
       "      <td>Household</td>\n",
       "      <td>151.4024</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FDD59</td>\n",
       "      <td>10.500</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Starchy Foods</td>\n",
       "      <td>78.2960</td>\n",
       "      <td>OUT046</td>\n",
       "      <td>1997</td>\n",
       "      <td>Small</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FDQ52</td>\n",
       "      <td>17.000</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.119571</td>\n",
       "      <td>Frozen Foods</td>\n",
       "      <td>249.7434</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FDP09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.033726</td>\n",
       "      <td>Snack Foods</td>\n",
       "      <td>211.6902</td>\n",
       "      <td>OUT027</td>\n",
       "      <td>1985</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FDK24</td>\n",
       "      <td>9.195</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.101276</td>\n",
       "      <td>Baking Goods</td>\n",
       "      <td>46.4744</td>\n",
       "      <td>OUT035</td>\n",
       "      <td>2004</td>\n",
       "      <td>Small</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Item_Identifier  Item_Weight Item_Fat_Content  Item_Visibility  \\\n",
       "0           NCF31        9.130          Low Fat         0.051928   \n",
       "1           FDD59       10.500          Regular         0.000000   \n",
       "2           FDQ52       17.000          Low Fat         0.119571   \n",
       "3           FDP09          NaN          Low Fat         0.033726   \n",
       "4           FDK24        9.195          Low Fat         0.101276   \n",
       "\n",
       "       Item_Type  Item_MRP Outlet_Identifier  Outlet_Establishment_Year  \\\n",
       "0      Household  151.4024            OUT049                       1999   \n",
       "1  Starchy Foods   78.2960            OUT046                       1997   \n",
       "2   Frozen Foods  249.7434            OUT049                       1999   \n",
       "3    Snack Foods  211.6902            OUT027                       1985   \n",
       "4   Baking Goods   46.4744            OUT035                       2004   \n",
       "\n",
       "  Outlet_Size Outlet_Location_Type        Outlet_Type  Item_Outlet_Sales  \n",
       "0      Medium               Tier 1  Supermarket Type1                NaN  \n",
       "1       Small               Tier 1  Supermarket Type1                NaN  \n",
       "2      Medium               Tier 1  Supermarket Type1                NaN  \n",
       "3      Medium               Tier 3  Supermarket Type3                NaN  \n",
       "4       Small               Tier 2  Supermarket Type1                NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e53593",
   "metadata": {},
   "source": [
    "The value range difference tells us that the dataset should be normalized.<br>\n",
    "I'd also like to investigate more the minimum values of <b>Item_Visibility</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f6f21a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4182.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12.959605</td>\n",
       "      <td>0.065671</td>\n",
       "      <td>141.344520</td>\n",
       "      <td>1997.900800</td>\n",
       "      <td>2188.381667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.661704</td>\n",
       "      <td>0.051206</td>\n",
       "      <td>62.401514</td>\n",
       "      <td>8.290423</td>\n",
       "      <td>1703.131187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.555000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.290000</td>\n",
       "      <td>1985.000000</td>\n",
       "      <td>33.290000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.890000</td>\n",
       "      <td>0.026839</td>\n",
       "      <td>94.119250</td>\n",
       "      <td>1987.000000</td>\n",
       "      <td>846.231800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>12.800000</td>\n",
       "      <td>0.054251</td>\n",
       "      <td>143.315400</td>\n",
       "      <td>1999.000000</td>\n",
       "      <td>1808.312800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>17.100000</td>\n",
       "      <td>0.093850</td>\n",
       "      <td>186.472700</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>3091.975200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>21.350000</td>\n",
       "      <td>0.328391</td>\n",
       "      <td>266.888400</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>11445.102000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Item_Weight  Item_Visibility     Item_MRP  Outlet_Establishment_Year  \\\n",
       "count  4182.000000      5000.000000  5000.000000                5000.000000   \n",
       "mean     12.959605         0.065671   141.344520                1997.900800   \n",
       "std       4.661704         0.051206    62.401514                   8.290423   \n",
       "min       4.555000         0.000000    31.290000                1985.000000   \n",
       "25%       8.890000         0.026839    94.119250                1987.000000   \n",
       "50%      12.800000         0.054251   143.315400                1999.000000   \n",
       "75%      17.100000         0.093850   186.472700                2004.000000   \n",
       "max      21.350000         0.328391   266.888400                2009.000000   \n",
       "\n",
       "       Item_Outlet_Sales  \n",
       "count        5000.000000  \n",
       "mean         2188.381667  \n",
       "std          1703.131187  \n",
       "min            33.290000  \n",
       "25%           846.231800  \n",
       "50%          1808.312800  \n",
       "75%          3091.975200  \n",
       "max         11445.102000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5fa839a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2878.000000</td>\n",
       "      <td>3523.000000</td>\n",
       "      <td>3523.000000</td>\n",
       "      <td>3523.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12.709487</td>\n",
       "      <td>0.066786</td>\n",
       "      <td>140.493580</td>\n",
       "      <td>1997.734033</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.613606</td>\n",
       "      <td>0.052149</td>\n",
       "      <td>62.100594</td>\n",
       "      <td>8.486081</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.555000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.490000</td>\n",
       "      <td>1985.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.630000</td>\n",
       "      <td>0.027577</td>\n",
       "      <td>93.496200</td>\n",
       "      <td>1987.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>12.500000</td>\n",
       "      <td>0.053482</td>\n",
       "      <td>142.481200</td>\n",
       "      <td>1999.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>16.700000</td>\n",
       "      <td>0.095462</td>\n",
       "      <td>184.658200</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>21.350000</td>\n",
       "      <td>0.311090</td>\n",
       "      <td>266.888400</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Item_Weight  Item_Visibility     Item_MRP  Outlet_Establishment_Year  \\\n",
       "count  2878.000000      3523.000000  3523.000000                3523.000000   \n",
       "mean     12.709487         0.066786   140.493580                1997.734033   \n",
       "std       4.613606         0.052149    62.100594                   8.486081   \n",
       "min       4.555000         0.000000    31.490000                1985.000000   \n",
       "25%       8.630000         0.027577    93.496200                1987.000000   \n",
       "50%      12.500000         0.053482   142.481200                1999.000000   \n",
       "75%      16.700000         0.095462   184.658200                2004.000000   \n",
       "max      21.350000         0.311090   266.888400                2009.000000   \n",
       "\n",
       "       Item_Outlet_Sales  \n",
       "count                0.0  \n",
       "mean                 NaN  \n",
       "std                  NaN  \n",
       "min                  NaN  \n",
       "25%                  NaN  \n",
       "50%                  NaN  \n",
       "75%                  NaN  \n",
       "max                  NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cea8bdc",
   "metadata": {},
   "source": [
    "Checking the data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38ebbcac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Item_Identifier               object\n",
       "Item_Weight                  float64\n",
       "Item_Fat_Content              object\n",
       "Item_Visibility              float64\n",
       "Item_Type                     object\n",
       "Item_MRP                     float64\n",
       "Outlet_Identifier             object\n",
       "Outlet_Establishment_Year      int64\n",
       "Outlet_Size                   object\n",
       "Outlet_Location_Type          object\n",
       "Outlet_Type                   object\n",
       "Item_Outlet_Sales            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f84f977e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Item_Identifier               object\n",
       "Item_Weight                  float64\n",
       "Item_Fat_Content              object\n",
       "Item_Visibility              float64\n",
       "Item_Type                     object\n",
       "Item_MRP                     float64\n",
       "Outlet_Identifier             object\n",
       "Outlet_Establishment_Year      int64\n",
       "Outlet_Size                   object\n",
       "Outlet_Location_Type          object\n",
       "Outlet_Type                   object\n",
       "Item_Outlet_Sales            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4722d977",
   "metadata": {},
   "source": [
    "Checking for null-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d8428c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Item_Identifier                 0\n",
       "Item_Weight                   818\n",
       "Item_Fat_Content                0\n",
       "Item_Visibility                 0\n",
       "Item_Type                       0\n",
       "Item_MRP                        0\n",
       "Outlet_Identifier               0\n",
       "Outlet_Establishment_Year       0\n",
       "Outlet_Size                  1439\n",
       "Outlet_Location_Type            0\n",
       "Outlet_Type                     0\n",
       "Item_Outlet_Sales               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f22f3ea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Item_Identifier                 0\n",
       "Item_Weight                   645\n",
       "Item_Fat_Content                0\n",
       "Item_Visibility                 0\n",
       "Item_Type                       0\n",
       "Item_MRP                        0\n",
       "Outlet_Identifier               0\n",
       "Outlet_Establishment_Year       0\n",
       "Outlet_Size                   971\n",
       "Outlet_Location_Type            0\n",
       "Outlet_Type                     0\n",
       "Item_Outlet_Sales            3523\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c92ac84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e6a6c6",
   "metadata": {},
   "source": [
    "Listing categorical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b64a5465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Low Fat', 'Regular', 'low fat', 'LF', 'reg']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Item_Fat_Content'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cb94970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Low Fat', 'Regular', 'reg', 'LF', 'low fat']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Item_Fat_Content'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28e48081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dairy',\n",
       " 'Soft Drinks',\n",
       " 'Meat',\n",
       " 'Fruits and Vegetables',\n",
       " 'Household',\n",
       " 'Baking Goods',\n",
       " 'Snack Foods',\n",
       " 'Frozen Foods',\n",
       " 'Breakfast',\n",
       " 'Health and Hygiene',\n",
       " 'Hard Drinks',\n",
       " 'Canned',\n",
       " 'Breads',\n",
       " 'Starchy Foods',\n",
       " 'Others',\n",
       " 'Seafood']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Item_Type'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5526db86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Household',\n",
       " 'Starchy Foods',\n",
       " 'Frozen Foods',\n",
       " 'Snack Foods',\n",
       " 'Baking Goods',\n",
       " 'Fruits and Vegetables',\n",
       " 'Canned',\n",
       " 'Soft Drinks',\n",
       " 'Health and Hygiene',\n",
       " 'Dairy',\n",
       " 'Meat',\n",
       " 'Seafood',\n",
       " 'Hard Drinks',\n",
       " 'Breads',\n",
       " 'Others',\n",
       " 'Breakfast']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Item_Type'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28b548d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Medium', nan, 'High', 'Small']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Outlet_Size'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d11a5e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Medium', 'Small', nan, 'High']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Outlet_Size'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3395882f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tier 1', 'Tier 3', 'Tier 2']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Outlet_Location_Type'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d44274c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tier 1', 'Tier 3', 'Tier 2']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Outlet_Location_Type'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f999ff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Supermarket Type1',\n",
       " 'Supermarket Type2',\n",
       " 'Grocery Store',\n",
       " 'Supermarket Type3']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Outlet_Type'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8de8ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Supermarket Type1',\n",
       " 'Supermarket Type3',\n",
       " 'Grocery Store',\n",
       " 'Supermarket Type2']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Outlet_Type'].unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377d0796",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "Reference source<br>\n",
    "https://towardsdatascience.com/preprocessing-with-sklearn-a-complete-and-comprehensive-guide-670cb98fcfb9\n",
    "## Null-values\n",
    "Replacing null values with the mean value for <b>Item_Weight</b> and the middle value <i>Medium</i> for <b>Outlet_Size</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05bf0424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Item_Weight'] = train['Item_Weight'].fillna(train['Item_Weight'].mean())\n",
    "train['Outlet_Size'] = train['Outlet_Size'].fillna('Medium')\n",
    "train.isnull().any().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95be3d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Item_Weight'] = train['Item_Weight'].fillna(test['Item_Weight'].mean())\n",
    "test['Outlet_Size'] = train['Outlet_Size'].fillna('Medium')\n",
    "test.drop(['Item_Outlet_Sales'], axis=1).isnull().any().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af70d55",
   "metadata": {},
   "source": [
    "## Unique values\n",
    "Removing item identifier values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e9eecbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['Item_Identifier'], axis=1, inplace=True)\n",
    "test.drop(['Item_Identifier'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b44d14",
   "metadata": {},
   "source": [
    "## Category features\n",
    "These must be <b>cleaned</b>, <b>screened</b> and <b>converted</b>.<br>\n",
    "How they are converted is based on the type they are, <b>ordinal</b> or <b>nominal</b>.<br>\n",
    "An ordinal feature has natural, ordered categories and the distance between each is not known.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee199d1c",
   "metadata": {},
   "source": [
    "### Category cleaning\n",
    "Before converting, I'll merge category variants of the same type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6b43d63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Low Fat', 'Regular', 'low fat', 'LF', 'reg']\n",
      "['Low Fat', 'Regular']\n"
     ]
    }
   ],
   "source": [
    "print(train['Item_Fat_Content'].unique().tolist())\n",
    "train['Item_Fat_Content'] = train['Item_Fat_Content'].replace('low fat', 'Low Fat')\n",
    "train['Item_Fat_Content'] = train['Item_Fat_Content'].replace('LF', 'Low Fat')\n",
    "train['Item_Fat_Content'] = train['Item_Fat_Content'].replace('reg', 'Regular')\n",
    "print(train['Item_Fat_Content'].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2bbcf69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Low Fat', 'Regular', 'reg', 'LF', 'low fat']\n",
      "['Low Fat', 'Regular']\n"
     ]
    }
   ],
   "source": [
    "print(test['Item_Fat_Content'].unique().tolist())\n",
    "test['Item_Fat_Content'] = test['Item_Fat_Content'].replace('low fat', 'Low Fat')\n",
    "test['Item_Fat_Content'] = test['Item_Fat_Content'].replace('LF', 'Low Fat')\n",
    "test['Item_Fat_Content'] = test['Item_Fat_Content'].replace('reg', 'Regular')\n",
    "print(test['Item_Fat_Content'].unique().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d20954",
   "metadata": {},
   "source": [
    "### Category screening\n",
    "Get a list of unique category types and list the number of values for each one.<br>\n",
    "If a category has too few values, it might make it harder to predict accurate prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f553d51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Low Fat', 'Regular']\n",
      "[3253, 1747]\n"
     ]
    }
   ],
   "source": [
    "categories = train[\"Item_Fat_Content\"].value_counts().keys().tolist()\n",
    "counts = train[\"Item_Fat_Content\"].value_counts().tolist()\n",
    "print(categories)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e0ed5e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Low Fat', 'Regular']\n",
      "[2264, 1259]\n"
     ]
    }
   ],
   "source": [
    "categories = test[\"Item_Fat_Content\"].value_counts().keys().tolist()\n",
    "counts = test[\"Item_Fat_Content\"].value_counts().tolist()\n",
    "print(categories)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9cf922e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fruits and Vegetables', 'Snack Foods', 'Household', 'Frozen Foods', 'Dairy', 'Canned', 'Baking Goods', 'Health and Hygiene', 'Soft Drinks', 'Meat', 'Breads', 'Hard Drinks', 'Others', 'Starchy Foods', 'Breakfast', 'Seafood']\n",
      "[733, 702, 532, 515, 401, 389, 370, 274, 265, 251, 153, 128, 96, 86, 66, 39]\n"
     ]
    }
   ],
   "source": [
    "categories = train['Item_Type'].value_counts().keys().tolist()\n",
    "counts = train['Item_Type'].value_counts().tolist()\n",
    "print(categories)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b178b3",
   "metadata": {},
   "source": [
    "The results from Item_Types in the train dataset shows that this column contains the categories with few values.<br>\n",
    "Consider removal of some of the categories to see if it makes a noticable difference in predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e6a1e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fruits and Vegetables', 'Snack Foods', 'Household', 'Frozen Foods', 'Dairy', 'Baking Goods', 'Canned', 'Health and Hygiene', 'Soft Drinks', 'Meat', 'Breads', 'Hard Drinks', 'Others', 'Starchy Foods', 'Breakfast', 'Seafood']\n",
      "[499, 498, 378, 341, 281, 278, 260, 246, 180, 174, 98, 86, 73, 62, 44, 25]\n"
     ]
    }
   ],
   "source": [
    "categories = test['Item_Type'].value_counts().keys().tolist()\n",
    "counts = test['Item_Type'].value_counts().tolist()\n",
    "print(categories)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "808a26da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1985, 2002, 1997, 2004, 1987, 2007, 1999, 2009, 1998]\n",
      "[818, 569, 559, 559, 558, 542, 541, 526, 328]\n"
     ]
    }
   ],
   "source": [
    "categories = train['Outlet_Establishment_Year'].value_counts().keys().tolist()\n",
    "counts = train['Outlet_Establishment_Year'].value_counts().tolist()\n",
    "print(categories)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4b332853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1985, 2009, 1999, 2007, 1987, 1997, 2004, 2002, 1998]\n",
      "[645, 402, 389, 384, 374, 371, 371, 360, 227]\n"
     ]
    }
   ],
   "source": [
    "categories = test['Outlet_Establishment_Year'].value_counts().keys().tolist()\n",
    "counts = test['Outlet_Establishment_Year'].value_counts().tolist()\n",
    "print(categories)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8abe56d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Medium', 'Small', 'High']\n",
      "[3044, 1398, 558]\n"
     ]
    }
   ],
   "source": [
    "categories = train['Outlet_Size'].value_counts().keys().tolist()\n",
    "counts = train['Outlet_Size'].value_counts().tolist()\n",
    "print(categories)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8333904b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Medium', 'Small', 'High']\n",
      "[2125, 1009, 389]\n"
     ]
    }
   ],
   "source": [
    "categories = test['Outlet_Size'].value_counts().keys().tolist()\n",
    "counts = test['Outlet_Size'].value_counts().tolist()\n",
    "print(categories)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "23a4b8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tier 3', 'Tier 2', 'Tier 1']\n",
      "[1950, 1670, 1380]\n"
     ]
    }
   ],
   "source": [
    "categories = train['Outlet_Location_Type'].value_counts().keys().tolist()\n",
    "counts = train['Outlet_Location_Type'].value_counts().tolist()\n",
    "print(categories)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1323d04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tier 3', 'Tier 2', 'Tier 1']\n",
      "[1400, 1115, 1008]\n"
     ]
    }
   ],
   "source": [
    "categories = test['Outlet_Location_Type'].value_counts().keys().tolist()\n",
    "counts = test['Outlet_Location_Type'].value_counts().tolist()\n",
    "print(categories)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0e167e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Supermarket Type1', 'Grocery Store', 'Supermarket Type3', 'Supermarket Type2']\n",
      "[3328, 608, 538, 526]\n"
     ]
    }
   ],
   "source": [
    "categories = train['Outlet_Type'].value_counts().keys().tolist()\n",
    "counts = train['Outlet_Type'].value_counts().tolist()\n",
    "print(categories)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9a9fddaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Supermarket Type1', 'Grocery Store', 'Supermarket Type2', 'Supermarket Type3']\n",
      "[2249, 475, 402, 397]\n"
     ]
    }
   ],
   "source": [
    "categories = test['Outlet_Type'].value_counts().keys().tolist()\n",
    "counts = test['Outlet_Type'].value_counts().tolist()\n",
    "print(categories)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a32f6f5",
   "metadata": {},
   "source": [
    "### Ordinal conversion\n",
    "Convertion of ordinal category types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5611a242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Low Fat', 'Regular']\n",
      "[0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(train['Item_Fat_Content'].unique().tolist())\n",
    "train['Item_Fat_Content'] = pd.factorize(train['Item_Fat_Content'])[0]\n",
    "print(train['Item_Fat_Content'].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "febc6bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Low Fat', 'Regular']\n",
      "[0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(test['Item_Fat_Content'].unique().tolist())\n",
    "test['Item_Fat_Content'] = pd.factorize(test['Item_Fat_Content'])[0]\n",
    "print(test['Item_Fat_Content'].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "08f6299c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Small', 'Medium', 'High']\n",
      "[0, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "train = train.sort_values('Outlet_Size', ascending=False) # Sorting to get the right order\n",
    "print(train['Outlet_Size'].unique().tolist())\n",
    "train['Outlet_Size'] = pd.factorize(train['Outlet_Size'])[0]\n",
    "print(train['Outlet_Size'].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d0d68f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Small', 'Medium', 'High']\n",
      "[0, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "test = test.sort_values('Outlet_Size', ascending=False)\n",
    "print(test['Outlet_Size'].unique().tolist())\n",
    "test['Outlet_Size'] = pd.factorize(test['Outlet_Size'])[0]\n",
    "print(test['Outlet_Size'].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e0b0c7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tier 1', 'Tier 2', 'Tier 3']\n",
      "[0, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "train = train.sort_values('Outlet_Location_Type', ascending=True)\n",
    "print(train['Outlet_Location_Type'].unique().tolist())\n",
    "train['Outlet_Location_Type'] = pd.factorize(train['Outlet_Location_Type'])[0]\n",
    "print(train['Outlet_Location_Type'].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "23e6b575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tier 1', 'Tier 2', 'Tier 3']\n",
      "[0, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "test = test.sort_values('Outlet_Location_Type', ascending=True)\n",
    "print(test['Outlet_Location_Type'].unique().tolist())\n",
    "test['Outlet_Location_Type'] = pd.factorize(test['Outlet_Location_Type'])[0]\n",
    "print(test['Outlet_Location_Type'].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8a6a25c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Grocery Store', 'Supermarket Type1', 'Supermarket Type2', 'Supermarket Type3']\n",
      "[0, 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "train = train.sort_values('Outlet_Type', ascending=True)\n",
    "print(train['Outlet_Type'].unique().tolist())\n",
    "train['Outlet_Type'] = pd.factorize(train['Outlet_Type'])[0]\n",
    "print(train['Outlet_Type'].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "029252be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Grocery Store', 'Supermarket Type1', 'Supermarket Type2', 'Supermarket Type3']\n",
      "[0, 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "test = test.sort_values('Outlet_Type', ascending=True)\n",
    "print(test['Outlet_Type'].unique().tolist())\n",
    "test['Outlet_Type'] = pd.factorize(test['Outlet_Type'])[0]\n",
    "print(test['Outlet_Type'].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "748652e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "train = train.sort_index()\n",
    "test = test.sort_index()\n",
    "train.head()\n",
    "print(train['Item_Visibility'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661eb431",
   "metadata": {},
   "source": [
    "### Nominal conversion\n",
    "Because both datasets contain the same nominal categories, we can process them at the same time.\n",
    "\n",
    "OneHotEncoder reference<br>\n",
    "https://towardsdatascience.com/preprocessing-with-sklearn-a-complete-and-comprehensive-guide-670cb98fcfb9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5710462f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baking Goods</th>\n",
       "      <th>Breads</th>\n",
       "      <th>Breakfast</th>\n",
       "      <th>Canned</th>\n",
       "      <th>Dairy</th>\n",
       "      <th>Frozen Foods</th>\n",
       "      <th>Fruits and Vegetables</th>\n",
       "      <th>Hard Drinks</th>\n",
       "      <th>Health and Hygiene</th>\n",
       "      <th>Household</th>\n",
       "      <th>...</th>\n",
       "      <th>OUT010</th>\n",
       "      <th>OUT013</th>\n",
       "      <th>OUT017</th>\n",
       "      <th>OUT018</th>\n",
       "      <th>OUT019</th>\n",
       "      <th>OUT027</th>\n",
       "      <th>OUT035</th>\n",
       "      <th>OUT045</th>\n",
       "      <th>OUT046</th>\n",
       "      <th>OUT049</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Baking Goods  Breads  Breakfast  Canned  Dairy  Frozen Foods  \\\n",
       "0             0       0          0       0      1             0   \n",
       "1             0       0          0       0      0             0   \n",
       "2             0       0          0       0      0             0   \n",
       "3             0       0          0       0      0             0   \n",
       "4             0       0          0       0      0             0   \n",
       "\n",
       "   Fruits and Vegetables  Hard Drinks  Health and Hygiene  Household  ...  \\\n",
       "0                      0            0                   0          0  ...   \n",
       "1                      0            0                   0          0  ...   \n",
       "2                      0            0                   0          0  ...   \n",
       "3                      1            0                   0          0  ...   \n",
       "4                      0            0                   0          1  ...   \n",
       "\n",
       "   OUT010  OUT013  OUT017  OUT018  OUT019  OUT027  OUT035  OUT045  OUT046  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       1       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       1       0       0       0       0       0       0       0       0   \n",
       "4       0       1       0       0       0       0       0       0       0   \n",
       "\n",
       "   OUT049  \n",
       "0       1  \n",
       "1       0  \n",
       "2       1  \n",
       "3       0  \n",
       "4       0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot = OneHotEncoder(dtype=np.int64, sparse=True)\n",
    "\n",
    "cols = ['Item_Type', 'Outlet_Establishment_Year', 'Outlet_Identifier']\n",
    "\n",
    "# Both datasets share the same categories, so we can use the same lists\n",
    "item_types = train['Item_Type'].value_counts().keys().sort_values(ascending=True).tolist()\n",
    "year_numbers = train['Outlet_Establishment_Year'].value_counts().keys().sort_values(ascending=True).tolist()\n",
    "outlet_ids = train['Outlet_Identifier'].value_counts().keys().sort_values(ascending=True).tolist()\n",
    "\n",
    "train_nominals = pd.DataFrame(onehot.fit_transform(train[cols]).toarray(),\n",
    "                              columns=item_types + year_numbers + outlet_ids)\n",
    "test_nominals = pd.DataFrame(onehot.fit_transform(test[cols]).toarray(),\n",
    "                              columns=item_types + year_numbers + outlet_ids)\n",
    "\n",
    "train_nominals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "36dee32f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "      <th>Baking Goods</th>\n",
       "      <th>Breads</th>\n",
       "      <th>...</th>\n",
       "      <th>OUT010</th>\n",
       "      <th>OUT013</th>\n",
       "      <th>OUT017</th>\n",
       "      <th>OUT018</th>\n",
       "      <th>OUT019</th>\n",
       "      <th>OUT027</th>\n",
       "      <th>OUT035</th>\n",
       "      <th>OUT045</th>\n",
       "      <th>OUT046</th>\n",
       "      <th>OUT049</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>249.8092</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3735.1380</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.92</td>\n",
       "      <td>1</td>\n",
       "      <td>0.019278</td>\n",
       "      <td>48.2692</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>443.4228</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>141.6180</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2097.2700</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>182.0950</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>732.3800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>53.8614</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>994.7052</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Item_Weight  Item_Fat_Content  Item_Visibility  Item_MRP  Outlet_Size  \\\n",
       "0         9.30                 0         0.016047  249.8092            1   \n",
       "1         5.92                 1         0.019278   48.2692            1   \n",
       "2        17.50                 0         0.016760  141.6180            1   \n",
       "3        19.20                 1         0.000000  182.0950            1   \n",
       "4         8.93                 0         0.000000   53.8614            2   \n",
       "\n",
       "   Outlet_Location_Type  Outlet_Type  Item_Outlet_Sales  Baking Goods  Breads  \\\n",
       "0                     0            1          3735.1380             0       0   \n",
       "1                     2            2           443.4228             0       0   \n",
       "2                     0            1          2097.2700             0       0   \n",
       "3                     2            0           732.3800             0       0   \n",
       "4                     2            1           994.7052             0       0   \n",
       "\n",
       "   ...  OUT010  OUT013  OUT017  OUT018  OUT019  OUT027  OUT035  OUT045  \\\n",
       "0  ...       0       0       0       0       0       0       0       0   \n",
       "1  ...       0       0       0       1       0       0       0       0   \n",
       "2  ...       0       0       0       0       0       0       0       0   \n",
       "3  ...       1       0       0       0       0       0       0       0   \n",
       "4  ...       0       1       0       0       0       0       0       0   \n",
       "\n",
       "   OUT046  OUT049  \n",
       "0       0       1  \n",
       "1       0       0  \n",
       "2       0       1  \n",
       "3       0       0  \n",
       "4       0       0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join the nominal types with the existing dataset.\n",
    "train = pd.concat([train, train_nominals], axis=1)\n",
    "test = pd.concat([test, test_nominals], axis=1)\n",
    "\n",
    "# Remove the columns that have been converted\n",
    "train.drop(cols, axis=1, inplace=True)\n",
    "test.drop(cols, axis=1, inplace=True)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86755408",
   "metadata": {},
   "source": [
    "## Normalization\n",
    "Apply individual scaling to features in the range 0 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "95a1cd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeMinMax(data):\n",
    "    \n",
    "    # fit scaler on training data\n",
    "    scale = MinMaxScaler().fit(data)\n",
    "\n",
    "    # transform data\n",
    "    data_scale = pd.DataFrame(scale.transform(data), columns=data.columns)\n",
    "    \n",
    "    return data_scale, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8ff8baef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# colums that should be scaled\n",
    "norm_cols = ['Item_Weight', 'Item_Visibility', 'Item_MRP', 'Outlet_Size', 'Outlet_Location_Type', 'Outlet_Type']\n",
    "\n",
    "# separate non-scalable and scalable features\n",
    "train_non_norm_df = train.drop(norm_cols, axis=1)\n",
    "train_norm_df, train_scale = normalizeMinMax(train[norm_cols]) # apply scaling\n",
    "\n",
    "test_non_norm_df = test.drop(norm_cols, axis=1)\n",
    "test_norm_df, test_scale = normalizeMinMax(test[norm_cols])\n",
    "\n",
    "# join the two dataframes together again\n",
    "train_norm = pd.concat([train_non_norm_df, train_norm_df], axis=1)\n",
    "test_norm = pd.concat([test_non_norm_df, test_norm_df], axis=1)\n",
    "\n",
    "# exclude Item_Outlet_Sales from the input data\n",
    "train_X_norm = train_norm.drop('Item_Outlet_Sales', axis=1)\n",
    "test_X_norm = test_norm.drop('Item_Outlet_Sales', axis=1)\n",
    "\n",
    "# isolate Item_Outlet_Sales as target variable\n",
    "train_y_norm = train['Item_Outlet_Sales']\n",
    "test_y_norm = train['Item_Outlet_Sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "437a0a16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display a plot for the input data distribution\n",
    "sns.kdeplot(data=test_X_norm, legend=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2d3e25",
   "metadata": {},
   "source": [
    "# Architecture\n",
    "My deep learning model is a Multilayer Perceptron (MLP).<br>\n",
    "It uses the Sequential class with 2 hidden layers and the <i>RMSprop</i> algorithm as optimizer.<br>\n",
    "\n",
    "I choose to use the <i>ShuffleSplit</i> class to perform cross-validation.<br>\n",
    "This was especially usefull for training when trying out different parameters and algorithms due to the low amount of data in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "27153f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I set model creation up as a function in order to easily test different combinations of layers\n",
    "def create_new_model(num_neurons, num_inputs):\n",
    "    \n",
    "    model = Sequential()\n",
    "    for i in range(0, len(num_neurons)):\n",
    "        if i == 0:\n",
    "            model.add(Dense(num_neurons[i], input_dim=num_inputs, kernel_initializer='normal', activation=\"relu\"))\n",
    "        else:\n",
    "            model.add(Dense(num_neurons[i], kernel_initializer='normal', activation=\"relu\"))\n",
    "    model.add(Dense(1, activation=\"linear\"))\n",
    "    model.compile(loss=\"mse\", optimizer=tf.keras.optimizers.RMSprop(0.0025))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "22312536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function just encapsulates the whole process of running through the number of dataset splits,\n",
    "# model creation, training, prediction and storing of results.\n",
    "# returns the model with its weights\n",
    "def run_train_model(num_neurons, num_epochs, num_splits, test_size):\n",
    "\n",
    "    ss = ShuffleSplit(n_splits=num_splits, test_size=test_size, random_state=0)\n",
    "    n_samples = len(train_norm)\n",
    "    fold_var = 1\n",
    "\n",
    "    for train_index, val_index in ss.split(train_X_norm):\n",
    "\n",
    "        # split in training and testing sets\n",
    "        X_train = train_X_norm.iloc[train_index]\n",
    "        y_train = train_y_norm.iloc[train_index]\n",
    "        X_test = train_X_norm.iloc[val_index]\n",
    "        y_test = train_y_norm.iloc[val_index]\n",
    "\n",
    "        print(\"fold_var:\", fold_var, \", train_index: \", train_index[0:5], \", val_index: \", val_index[0:5])\n",
    "        print(\"X_train:\", X_train.shape, \", y_train:\", y_train.shape, \", X_test:\", X_test.shape, \"y_test:\", y_test.shape)\n",
    "\n",
    "        # create model\n",
    "        model = create_new_model(num_neurons, test_X_norm.shape[1])\n",
    "\n",
    "        # build model\n",
    "        history = model.fit(x=X_train, y=y_train, validation_data=(X_test, y_test), epochs=num_epochs)\n",
    "\n",
    "        # generate predictions\n",
    "        preds = model.predict(X_test)\n",
    "        R2_SCORES.append(r2_score(y_test, preds))\n",
    "        MAE.append(mean_absolute_error(y_test, preds))\n",
    "\n",
    "        # store data for plotting\n",
    "        LOSS.append(history.history['loss'])\n",
    "        VALIDATION_LOSS.append(history.history['val_loss'])\n",
    "\n",
    "        fold_var += 1\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a539a785",
   "metadata": {},
   "source": [
    "Here I configure some base options before starting the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "068a40f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold_var: 1 , train_index:  [4154 4820 1202 3759  622] , val_index:  [ 398 3833 4836 4572  636]\n",
      "X_train: (3750, 42) , y_train: (3750,) , X_test: (1250, 42) y_test: (1250,)\n",
      "Epoch 1/200\n",
      "118/118 [==============================] - 1s 3ms/step - loss: 7517763.5000 - val_loss: 7538104.0000\n",
      "Epoch 2/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 6813906.5000 - val_loss: 6427503.5000\n",
      "Epoch 3/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 5347984.5000 - val_loss: 4659520.5000\n",
      "Epoch 4/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 3516739.0000 - val_loss: 3021730.0000\n",
      "Epoch 5/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 2455687.5000 - val_loss: 2578456.5000\n",
      "Epoch 6/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 2259574.7500 - val_loss: 2453872.2500\n",
      "Epoch 7/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 2157453.0000 - val_loss: 2344786.5000\n",
      "Epoch 8/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 2064023.0000 - val_loss: 2243017.0000\n",
      "Epoch 9/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1979100.7500 - val_loss: 2152245.2500\n",
      "Epoch 10/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1900165.3750 - val_loss: 2066810.0000\n",
      "Epoch 11/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1829533.8750 - val_loss: 1996246.2500\n",
      "Epoch 12/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1770480.8750 - val_loss: 1936783.3750\n",
      "Epoch 13/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1715517.0000 - val_loss: 1883180.2500\n",
      "Epoch 14/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1664445.2500 - val_loss: 1830880.2500\n",
      "Epoch 15/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1619257.7500 - val_loss: 1786461.0000\n",
      "Epoch 16/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1574021.1250 - val_loss: 1739355.1250\n",
      "Epoch 17/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1531344.8750 - val_loss: 1691509.0000\n",
      "Epoch 18/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1490271.0000 - val_loss: 1647212.8750\n",
      "Epoch 19/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1452521.6250 - val_loss: 1607110.0000\n",
      "Epoch 20/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1415336.7500 - val_loss: 1571592.0000\n",
      "Epoch 21/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1378980.1250 - val_loss: 1528718.1250\n",
      "Epoch 22/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1347038.5000 - val_loss: 1494626.2500\n",
      "Epoch 23/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1316820.8750 - val_loss: 1462541.2500\n",
      "Epoch 24/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1288653.1250 - val_loss: 1430069.6250\n",
      "Epoch 25/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1261345.8750 - val_loss: 1396211.8750\n",
      "Epoch 26/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1239920.0000 - val_loss: 1376174.8750\n",
      "Epoch 27/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1220910.5000 - val_loss: 1360521.2500\n",
      "Epoch 28/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1209513.0000 - val_loss: 1344646.3750\n",
      "Epoch 29/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1198971.3750 - val_loss: 1333480.1250\n",
      "Epoch 30/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1190288.8750 - val_loss: 1315991.2500\n",
      "Epoch 31/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1182912.7500 - val_loss: 1310514.5000\n",
      "Epoch 32/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1178174.2500 - val_loss: 1299735.5000\n",
      "Epoch 33/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1173163.1250 - val_loss: 1295245.7500\n",
      "Epoch 34/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1169939.7500 - val_loss: 1296609.7500\n",
      "Epoch 35/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1166993.8750 - val_loss: 1288059.7500\n",
      "Epoch 36/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1165591.7500 - val_loss: 1286825.6250\n",
      "Epoch 37/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1163849.8750 - val_loss: 1283096.5000\n",
      "Epoch 38/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1163858.3750 - val_loss: 1282672.7500\n",
      "Epoch 39/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1162522.5000 - val_loss: 1279995.2500\n",
      "Epoch 40/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1161736.6250 - val_loss: 1280127.7500\n",
      "Epoch 41/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1160830.1250 - val_loss: 1277639.6250\n",
      "Epoch 42/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1159119.1250 - val_loss: 1279892.8750\n",
      "Epoch 43/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1159349.7500 - val_loss: 1286743.5000\n",
      "Epoch 44/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1159557.3750 - val_loss: 1278407.2500\n",
      "Epoch 45/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1158315.8750 - val_loss: 1274424.6250\n",
      "Epoch 46/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1157862.5000 - val_loss: 1273270.0000\n",
      "Epoch 47/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1157442.6250 - val_loss: 1275088.3750\n",
      "Epoch 48/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1156774.6250 - val_loss: 1275816.5000\n",
      "Epoch 49/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1156514.7500 - val_loss: 1278269.3750\n",
      "Epoch 50/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1155895.7500 - val_loss: 1274399.7500\n",
      "Epoch 51/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1154389.5000 - val_loss: 1279183.5000\n",
      "Epoch 52/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1156164.6250 - val_loss: 1272070.0000\n",
      "Epoch 53/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1154364.5000 - val_loss: 1273696.0000\n",
      "Epoch 54/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1155106.2500 - val_loss: 1272026.3750\n",
      "Epoch 55/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1154476.6250 - val_loss: 1272665.5000\n",
      "Epoch 56/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1154674.7500 - val_loss: 1273272.0000\n",
      "Epoch 57/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1153505.1250 - val_loss: 1275690.5000\n",
      "Epoch 58/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1154109.7500 - val_loss: 1275756.0000\n",
      "Epoch 59/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1153976.5000 - val_loss: 1269578.5000\n",
      "Epoch 60/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1152088.2500 - val_loss: 1276594.3750\n",
      "Epoch 61/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1151866.3750 - val_loss: 1279286.6250\n",
      "Epoch 62/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1153155.2500 - val_loss: 1271387.7500\n",
      "Epoch 63/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1152187.1250 - val_loss: 1272078.1250\n",
      "Epoch 64/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1150763.2500 - val_loss: 1279287.3750\n",
      "Epoch 65/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1151928.5000 - val_loss: 1273984.5000\n",
      "Epoch 66/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1151613.6250 - val_loss: 1267918.3750\n",
      "Epoch 67/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1151212.8750 - val_loss: 1266833.5000\n",
      "Epoch 68/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1150546.5000 - val_loss: 1274893.1250\n",
      "Epoch 69/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1151442.6250 - val_loss: 1271514.6250\n",
      "Epoch 70/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1149617.8750 - val_loss: 1268778.7500\n",
      "Epoch 71/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1150190.3750 - val_loss: 1264643.0000\n",
      "Epoch 72/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1150501.5000 - val_loss: 1265101.7500\n",
      "Epoch 73/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1149699.6250 - val_loss: 1274279.2500\n",
      "Epoch 74/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1148781.7500 - val_loss: 1266853.8750\n",
      "Epoch 75/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1148211.6250 - val_loss: 1265450.7500\n",
      "Epoch 76/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1148843.1250 - val_loss: 1263828.6250\n",
      "Epoch 77/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1148226.5000 - val_loss: 1261981.5000\n",
      "Epoch 78/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1147691.0000 - val_loss: 1263525.2500\n",
      "Epoch 79/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1146297.2500 - val_loss: 1264781.2500\n",
      "Epoch 80/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1147378.1250 - val_loss: 1262701.7500\n",
      "Epoch 81/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1147136.6250 - val_loss: 1260654.7500\n",
      "Epoch 82/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1144247.0000 - val_loss: 1274380.3750\n",
      "Epoch 83/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1146566.6250 - val_loss: 1260962.8750\n",
      "Epoch 84/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1144795.7500 - val_loss: 1259480.8750\n",
      "Epoch 85/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1145374.1250 - val_loss: 1258244.0000\n",
      "Epoch 86/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1145577.3750 - val_loss: 1257216.8750\n",
      "Epoch 87/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1143493.6250 - val_loss: 1262834.7500\n",
      "Epoch 88/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1144152.3750 - val_loss: 1260770.6250\n",
      "Epoch 89/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1143002.7500 - val_loss: 1266997.1250\n",
      "Epoch 90/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1144111.6250 - val_loss: 1263364.0000\n",
      "Epoch 91/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1144024.1250 - val_loss: 1258575.6250\n",
      "Epoch 92/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1142363.0000 - val_loss: 1259745.1250\n",
      "Epoch 93/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1142661.5000 - val_loss: 1257040.5000\n",
      "Epoch 94/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1142851.0000 - val_loss: 1256533.2500\n",
      "Epoch 95/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1141453.2500 - val_loss: 1258429.0000\n",
      "Epoch 96/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1141932.6250 - val_loss: 1258527.7500\n",
      "Epoch 97/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1140730.1250 - val_loss: 1255110.7500\n",
      "Epoch 98/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1138500.0000 - val_loss: 1268521.0000\n",
      "Epoch 99/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1140609.0000 - val_loss: 1258091.5000\n",
      "Epoch 100/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1140462.2500 - val_loss: 1254565.1250\n",
      "Epoch 101/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1139668.7500 - val_loss: 1257643.5000\n",
      "Epoch 102/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1139141.1250 - val_loss: 1258542.6250\n",
      "Epoch 103/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1139203.3750 - val_loss: 1253887.3750\n",
      "Epoch 104/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1139201.2500 - val_loss: 1253424.3750\n",
      "Epoch 105/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1139483.8750 - val_loss: 1256252.2500\n",
      "Epoch 106/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1137933.5000 - val_loss: 1254414.7500\n",
      "Epoch 107/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1138155.2500 - val_loss: 1255988.1250\n",
      "Epoch 108/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1137700.5000 - val_loss: 1255608.7500\n",
      "Epoch 109/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1137047.5000 - val_loss: 1254112.6250\n",
      "Epoch 110/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1137166.3750 - val_loss: 1255233.2500\n",
      "Epoch 111/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1137124.2500 - val_loss: 1252409.8750\n",
      "Epoch 112/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1137094.3750 - val_loss: 1253547.7500\n",
      "Epoch 113/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1136681.8750 - val_loss: 1255075.8750\n",
      "Epoch 114/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1136224.0000 - val_loss: 1255448.2500\n",
      "Epoch 115/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1136375.7500 - val_loss: 1254244.6250\n",
      "Epoch 116/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1136550.2500 - val_loss: 1255958.5000\n",
      "Epoch 117/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1135555.0000 - val_loss: 1257829.2500\n",
      "Epoch 118/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1135745.3750 - val_loss: 1251661.1250\n",
      "Epoch 119/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1135010.5000 - val_loss: 1252227.8750\n",
      "Epoch 120/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1135064.3750 - val_loss: 1255176.7500\n",
      "Epoch 121/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1134622.0000 - val_loss: 1251681.5000\n",
      "Epoch 122/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1133746.6250 - val_loss: 1252078.7500\n",
      "Epoch 123/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1133455.2500 - val_loss: 1256969.6250\n",
      "Epoch 124/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1133891.6250 - val_loss: 1250232.8750\n",
      "Epoch 125/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1133703.7500 - val_loss: 1251275.7500\n",
      "Epoch 126/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1133398.0000 - val_loss: 1250262.5000\n",
      "Epoch 127/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1133262.0000 - val_loss: 1252053.1250\n",
      "Epoch 128/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1133384.2500 - val_loss: 1254632.1250\n",
      "Epoch 129/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1133297.6250 - val_loss: 1251458.7500\n",
      "Epoch 130/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1132298.5000 - val_loss: 1249318.7500\n",
      "Epoch 131/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1132670.3750 - val_loss: 1250609.1250\n",
      "Epoch 132/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1131869.8750 - val_loss: 1252258.8750\n",
      "Epoch 133/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1132327.6250 - val_loss: 1249233.7500\n",
      "Epoch 134/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1132208.7500 - val_loss: 1251635.1250\n",
      "Epoch 135/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1130779.8750 - val_loss: 1256735.3750\n",
      "Epoch 136/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1131666.8750 - val_loss: 1253268.8750\n",
      "Epoch 137/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1131333.3750 - val_loss: 1249120.3750\n",
      "Epoch 138/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1131214.1250 - val_loss: 1251692.5000\n",
      "Epoch 139/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1129584.3750 - val_loss: 1251183.7500\n",
      "Epoch 140/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1130186.6250 - val_loss: 1250157.0000\n",
      "Epoch 141/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1129985.2500 - val_loss: 1249369.0000\n",
      "Epoch 142/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1130003.5000 - val_loss: 1257207.3750\n",
      "Epoch 143/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1129234.1250 - val_loss: 1252661.5000\n",
      "Epoch 144/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1128257.3750 - val_loss: 1248779.0000\n",
      "Epoch 145/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1128138.6250 - val_loss: 1248356.1250\n",
      "Epoch 146/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1128994.2500 - val_loss: 1248414.1250\n",
      "Epoch 147/200\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 1128599.5000 - val_loss: 1250033.5000\n",
      "Epoch 148/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1128392.7500 - val_loss: 1248229.8750\n",
      "Epoch 149/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1128315.5000 - val_loss: 1254029.8750\n",
      "Epoch 150/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1127010.0000 - val_loss: 1247210.0000\n",
      "Epoch 151/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1126235.1250 - val_loss: 1248258.2500\n",
      "Epoch 152/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1127854.0000 - val_loss: 1250136.0000\n",
      "Epoch 153/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1127053.6250 - val_loss: 1252523.7500\n",
      "Epoch 154/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1126108.5000 - val_loss: 1264579.1250\n",
      "Epoch 155/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1126934.6250 - val_loss: 1252906.0000\n",
      "Epoch 156/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1126971.3750 - val_loss: 1249290.6250\n",
      "Epoch 157/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1126966.8750 - val_loss: 1247823.7500\n",
      "Epoch 158/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1126793.0000 - val_loss: 1249139.8750\n",
      "Epoch 159/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1126331.0000 - val_loss: 1251147.3750\n",
      "Epoch 160/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1125295.0000 - val_loss: 1247896.8750\n",
      "Epoch 161/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1125044.7500 - val_loss: 1249607.3750\n",
      "Epoch 162/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1124953.7500 - val_loss: 1248364.2500\n",
      "Epoch 163/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1124975.2500 - val_loss: 1250103.7500\n",
      "Epoch 164/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1125398.5000 - val_loss: 1247985.5000\n",
      "Epoch 165/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1125097.3750 - val_loss: 1246684.6250\n",
      "Epoch 166/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1124955.2500 - val_loss: 1251031.6250\n",
      "Epoch 167/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1123776.3750 - val_loss: 1245952.2500\n",
      "Epoch 168/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1124488.7500 - val_loss: 1247284.1250\n",
      "Epoch 169/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1124380.2500 - val_loss: 1247252.1250\n",
      "Epoch 170/200\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 1123105.2500 - val_loss: 1253774.0000\n",
      "Epoch 171/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1124488.2500 - val_loss: 1253099.8750\n",
      "Epoch 172/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1123615.0000 - val_loss: 1245524.3750\n",
      "Epoch 173/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1120407.8750 - val_loss: 1246873.3750\n",
      "Epoch 174/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1123269.6250 - val_loss: 1246387.8750\n",
      "Epoch 175/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1122068.1250 - val_loss: 1258064.7500\n",
      "Epoch 176/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1123146.7500 - val_loss: 1249001.2500\n",
      "Epoch 177/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1122144.7500 - val_loss: 1246625.2500\n",
      "Epoch 178/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1121083.8750 - val_loss: 1262157.1250\n",
      "Epoch 179/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1122167.8750 - val_loss: 1245783.5000\n",
      "Epoch 180/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1122673.7500 - val_loss: 1244723.5000\n",
      "Epoch 181/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1122495.1250 - val_loss: 1244445.7500\n",
      "Epoch 182/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1121358.2500 - val_loss: 1249548.7500\n",
      "Epoch 183/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1121849.5000 - val_loss: 1252877.6250\n",
      "Epoch 184/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1122208.6250 - val_loss: 1246276.5000\n",
      "Epoch 185/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1121195.7500 - val_loss: 1246528.0000\n",
      "Epoch 186/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1120468.7500 - val_loss: 1244988.1250\n",
      "Epoch 187/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1121666.2500 - val_loss: 1247038.6250\n",
      "Epoch 188/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1121366.2500 - val_loss: 1244463.3750\n",
      "Epoch 189/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1120849.0000 - val_loss: 1246427.5000\n",
      "Epoch 190/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1120976.3750 - val_loss: 1245872.2500\n",
      "Epoch 191/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1119875.2500 - val_loss: 1245283.3750\n",
      "Epoch 192/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1121010.2500 - val_loss: 1248752.7500\n",
      "Epoch 193/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1120700.1250 - val_loss: 1245849.7500\n",
      "Epoch 194/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1118527.5000 - val_loss: 1244600.8750\n",
      "Epoch 195/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1119398.3750 - val_loss: 1251486.2500\n",
      "Epoch 196/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1120777.8750 - val_loss: 1247795.0000\n",
      "Epoch 197/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1119013.2500 - val_loss: 1244517.8750\n",
      "Epoch 198/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1119801.1250 - val_loss: 1244603.6250\n",
      "Epoch 199/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1117414.0000 - val_loss: 1244557.6250\n",
      "Epoch 200/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1119320.5000 - val_loss: 1248869.5000\n",
      "40/40 [==============================] - 0s 1ms/step\n",
      "fold_var: 2 , train_index:  [3435 3339 3344  146 2282] , val_index:  [ 597  332  521 3935 4800]\n",
      "X_train: (3750, 42) , y_train: (3750,) , X_test: (1250, 42) y_test: (1250,)\n",
      "Epoch 1/200\n",
      "118/118 [==============================] - 1s 4ms/step - loss: 7340736.5000 - val_loss: 8192587.5000\n",
      "Epoch 2/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 6763892.5000 - val_loss: 7183242.0000\n",
      "Epoch 3/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 5467253.5000 - val_loss: 5435255.5000\n",
      "Epoch 4/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 3775358.7500 - val_loss: 3536799.0000\n",
      "Epoch 5/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 2575367.0000 - val_loss: 2685693.7500\n",
      "Epoch 6/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 2286229.2500 - val_loss: 2530225.5000\n",
      "Epoch 7/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 2182671.0000 - val_loss: 2427550.2500\n",
      "Epoch 8/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 2089507.3750 - val_loss: 2325531.2500\n",
      "Epoch 9/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 2002321.6250 - val_loss: 2239087.5000\n",
      "Epoch 10/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1924404.8750 - val_loss: 2155715.7500\n",
      "Epoch 11/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1851238.5000 - val_loss: 2075050.3750\n",
      "Epoch 12/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1788509.6250 - val_loss: 2033259.8750\n",
      "Epoch 13/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1734961.0000 - val_loss: 1971211.8750\n",
      "Epoch 14/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1682865.3750 - val_loss: 1897544.7500\n",
      "Epoch 15/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1633708.1250 - val_loss: 1860336.6250\n",
      "Epoch 16/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1590394.3750 - val_loss: 1798135.3750\n",
      "Epoch 17/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1548137.0000 - val_loss: 1751823.1250\n",
      "Epoch 18/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1509909.7500 - val_loss: 1719405.7500\n",
      "Epoch 19/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1471235.3750 - val_loss: 1688828.2500\n",
      "Epoch 20/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1436495.6250 - val_loss: 1635839.1250\n",
      "Epoch 21/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1397941.1250 - val_loss: 1595252.3750\n",
      "Epoch 22/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1362599.8750 - val_loss: 1555859.0000\n",
      "Epoch 23/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1330300.8750 - val_loss: 1513053.3750\n",
      "Epoch 24/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1301289.1250 - val_loss: 1478168.7500\n",
      "Epoch 25/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1275280.3750 - val_loss: 1449292.0000\n",
      "Epoch 26/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1251465.5000 - val_loss: 1454940.8750\n",
      "Epoch 27/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1232674.1250 - val_loss: 1401965.0000\n",
      "Epoch 28/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1214242.8750 - val_loss: 1384148.0000\n",
      "Epoch 29/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1201527.3750 - val_loss: 1373173.5000\n",
      "Epoch 30/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1190333.6250 - val_loss: 1359201.2500\n",
      "Epoch 31/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1181520.7500 - val_loss: 1366306.7500\n",
      "Epoch 32/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1175313.3750 - val_loss: 1350790.8750\n",
      "Epoch 33/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1169406.2500 - val_loss: 1336255.6250\n",
      "Epoch 34/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1163319.7500 - val_loss: 1358307.2500\n",
      "Epoch 35/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1161941.1250 - val_loss: 1337021.1250\n",
      "Epoch 36/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1158967.3750 - val_loss: 1323281.8750\n",
      "Epoch 37/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1156392.1250 - val_loss: 1313933.2500\n",
      "Epoch 38/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1155220.2500 - val_loss: 1323955.8750\n",
      "Epoch 39/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1153146.6250 - val_loss: 1319026.1250\n",
      "Epoch 40/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1151812.6250 - val_loss: 1327055.0000\n",
      "Epoch 41/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1151032.7500 - val_loss: 1306167.7500\n",
      "Epoch 42/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1150269.0000 - val_loss: 1314784.0000\n",
      "Epoch 43/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1148238.7500 - val_loss: 1330857.2500\n",
      "Epoch 44/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1148951.5000 - val_loss: 1311468.5000\n",
      "Epoch 45/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1147635.2500 - val_loss: 1300994.2500\n",
      "Epoch 46/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1145979.1250 - val_loss: 1304730.8750\n",
      "Epoch 47/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1147336.8750 - val_loss: 1308839.0000\n",
      "Epoch 48/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1145548.2500 - val_loss: 1307281.5000\n",
      "Epoch 49/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1145791.1250 - val_loss: 1307677.2500\n",
      "Epoch 50/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1144912.3750 - val_loss: 1323417.5000\n",
      "Epoch 51/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1143414.6250 - val_loss: 1297633.6250\n",
      "Epoch 52/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1143864.5000 - val_loss: 1320435.2500\n",
      "Epoch 53/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1144267.0000 - val_loss: 1306114.8750\n",
      "Epoch 54/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1143061.3750 - val_loss: 1308927.6250\n",
      "Epoch 55/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1142516.6250 - val_loss: 1316714.6250\n",
      "Epoch 56/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1140756.2500 - val_loss: 1292865.1250\n",
      "Epoch 57/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1141653.7500 - val_loss: 1305972.1250\n",
      "Epoch 58/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1140782.2500 - val_loss: 1301550.5000\n",
      "Epoch 59/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1141111.6250 - val_loss: 1299065.1250\n",
      "Epoch 60/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1139421.8750 - val_loss: 1307348.5000\n",
      "Epoch 61/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1139634.6250 - val_loss: 1303584.6250\n",
      "Epoch 62/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1139029.0000 - val_loss: 1294376.1250\n",
      "Epoch 63/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1138824.1250 - val_loss: 1311402.5000\n",
      "Epoch 64/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1138264.5000 - val_loss: 1308081.8750\n",
      "Epoch 65/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1138089.0000 - val_loss: 1301248.2500\n",
      "Epoch 66/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1136454.0000 - val_loss: 1298534.2500\n",
      "Epoch 67/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1137497.6250 - val_loss: 1305699.8750\n",
      "Epoch 68/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1135887.7500 - val_loss: 1312438.0000\n",
      "Epoch 69/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1135777.5000 - val_loss: 1311636.2500\n",
      "Epoch 70/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1135047.6250 - val_loss: 1309444.6250\n",
      "Epoch 71/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1134645.7500 - val_loss: 1289130.7500\n",
      "Epoch 72/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1133834.2500 - val_loss: 1286821.3750\n",
      "Epoch 73/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1133849.5000 - val_loss: 1294404.2500\n",
      "Epoch 74/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1134173.2500 - val_loss: 1296665.0000\n",
      "Epoch 75/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1133427.0000 - val_loss: 1291881.7500\n",
      "Epoch 76/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1133107.0000 - val_loss: 1294496.2500\n",
      "Epoch 77/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1131651.2500 - val_loss: 1289520.6250\n",
      "Epoch 78/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1132206.3750 - val_loss: 1298488.0000\n",
      "Epoch 79/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1131319.3750 - val_loss: 1291326.7500\n",
      "Epoch 80/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1131453.3750 - val_loss: 1303874.0000\n",
      "Epoch 81/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1130282.3750 - val_loss: 1304878.0000\n",
      "Epoch 82/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1128543.7500 - val_loss: 1324416.2500\n",
      "Epoch 83/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1129006.5000 - val_loss: 1291427.5000\n",
      "Epoch 84/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1126135.7500 - val_loss: 1294601.2500\n",
      "Epoch 85/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1127990.8750 - val_loss: 1289867.6250\n",
      "Epoch 86/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1128983.8750 - val_loss: 1294745.6250\n",
      "Epoch 87/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1127564.8750 - val_loss: 1294960.1250\n",
      "Epoch 88/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1127010.7500 - val_loss: 1288729.7500\n",
      "Epoch 89/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1126357.7500 - val_loss: 1289436.3750\n",
      "Epoch 90/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1126063.0000 - val_loss: 1294981.3750\n",
      "Epoch 91/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1126357.5000 - val_loss: 1300445.3750\n",
      "Epoch 92/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1125415.1250 - val_loss: 1289232.2500\n",
      "Epoch 93/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1125676.6250 - val_loss: 1288879.3750\n",
      "Epoch 94/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1124289.0000 - val_loss: 1287505.8750\n",
      "Epoch 95/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1125391.2500 - val_loss: 1297683.2500\n",
      "Epoch 96/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1124513.8750 - val_loss: 1297878.3750\n",
      "Epoch 97/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1124291.7500 - val_loss: 1295240.5000\n",
      "Epoch 98/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1123500.6250 - val_loss: 1297476.7500\n",
      "Epoch 99/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1123901.8750 - val_loss: 1302970.7500\n",
      "Epoch 100/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1122722.0000 - val_loss: 1302233.6250\n",
      "Epoch 101/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1122358.6250 - val_loss: 1297851.1250\n",
      "Epoch 102/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1121482.8750 - val_loss: 1290065.6250\n",
      "Epoch 103/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1122059.7500 - val_loss: 1306368.7500\n",
      "Epoch 104/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1121250.3750 - val_loss: 1302257.8750\n",
      "Epoch 105/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1121331.6250 - val_loss: 1294615.6250\n",
      "Epoch 106/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1120253.8750 - val_loss: 1291621.3750\n",
      "Epoch 107/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1118913.6250 - val_loss: 1319535.8750\n",
      "Epoch 108/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1119819.0000 - val_loss: 1291390.1250\n",
      "Epoch 109/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1119208.7500 - val_loss: 1288213.3750\n",
      "Epoch 110/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1119009.6250 - val_loss: 1301710.3750\n",
      "Epoch 111/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1118854.8750 - val_loss: 1310194.8750\n",
      "Epoch 112/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1118244.8750 - val_loss: 1293442.5000\n",
      "Epoch 113/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1117942.2500 - val_loss: 1291775.2500\n",
      "Epoch 114/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1118160.7500 - val_loss: 1295471.1250\n",
      "Epoch 115/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1117242.8750 - val_loss: 1284399.7500\n",
      "Epoch 116/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1117042.3750 - val_loss: 1300280.8750\n",
      "Epoch 117/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1116334.8750 - val_loss: 1296790.1250\n",
      "Epoch 118/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1115629.1250 - val_loss: 1308823.6250\n",
      "Epoch 119/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1114703.6250 - val_loss: 1289079.2500\n",
      "Epoch 120/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1114684.7500 - val_loss: 1308265.2500\n",
      "Epoch 121/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1114440.6250 - val_loss: 1298691.2500\n",
      "Epoch 122/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1114174.6250 - val_loss: 1301165.8750\n",
      "Epoch 123/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1113252.8750 - val_loss: 1313043.7500\n",
      "Epoch 124/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1114041.0000 - val_loss: 1308296.0000\n",
      "Epoch 125/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1112552.1250 - val_loss: 1285273.2500\n",
      "Epoch 126/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1112756.1250 - val_loss: 1287312.1250\n",
      "Epoch 127/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1112800.3750 - val_loss: 1286972.3750\n",
      "Epoch 128/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1112124.3750 - val_loss: 1296757.0000\n",
      "Epoch 129/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1111853.6250 - val_loss: 1290533.1250\n",
      "Epoch 130/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1111031.7500 - val_loss: 1303314.6250\n",
      "Epoch 131/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1111295.7500 - val_loss: 1296854.2500\n",
      "Epoch 132/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1111544.7500 - val_loss: 1291482.8750\n",
      "Epoch 133/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1110471.5000 - val_loss: 1284536.2500\n",
      "Epoch 134/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1111409.7500 - val_loss: 1291503.2500\n",
      "Epoch 135/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1110688.1250 - val_loss: 1302018.2500\n",
      "Epoch 136/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1110075.1250 - val_loss: 1300364.2500\n",
      "Epoch 137/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1109734.7500 - val_loss: 1287343.7500\n",
      "Epoch 138/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1109498.0000 - val_loss: 1284102.1250\n",
      "Epoch 139/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1109904.0000 - val_loss: 1285093.5000\n",
      "Epoch 140/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1108505.8750 - val_loss: 1303099.1250\n",
      "Epoch 141/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1108958.2500 - val_loss: 1291452.2500\n",
      "Epoch 142/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1107312.3750 - val_loss: 1296387.0000\n",
      "Epoch 143/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1107589.6250 - val_loss: 1312828.3750\n",
      "Epoch 144/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1107568.7500 - val_loss: 1285548.8750\n",
      "Epoch 145/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1107712.6250 - val_loss: 1286579.6250\n",
      "Epoch 146/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1107101.7500 - val_loss: 1297602.3750\n",
      "Epoch 147/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1107147.1250 - val_loss: 1289476.8750\n",
      "Epoch 148/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1107387.3750 - val_loss: 1289165.2500\n",
      "Epoch 149/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1105521.7500 - val_loss: 1292743.5000\n",
      "Epoch 150/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1105641.8750 - val_loss: 1297147.1250\n",
      "Epoch 151/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1105744.3750 - val_loss: 1296431.1250\n",
      "Epoch 152/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1105804.0000 - val_loss: 1293042.7500\n",
      "Epoch 153/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1105829.6250 - val_loss: 1292419.0000\n",
      "Epoch 154/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1104265.1250 - val_loss: 1285718.3750\n",
      "Epoch 155/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1105352.0000 - val_loss: 1283384.8750\n",
      "Epoch 156/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1104810.2500 - val_loss: 1286142.0000\n",
      "Epoch 157/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1101515.8750 - val_loss: 1326200.0000\n",
      "Epoch 158/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1105188.1250 - val_loss: 1290267.3750\n",
      "Epoch 159/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1104074.5000 - val_loss: 1291520.7500\n",
      "Epoch 160/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1104564.8750 - val_loss: 1293784.6250\n",
      "Epoch 161/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1103654.1250 - val_loss: 1285802.3750\n",
      "Epoch 162/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1102562.1250 - val_loss: 1309535.7500\n",
      "Epoch 163/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1103820.1250 - val_loss: 1294587.5000\n",
      "Epoch 164/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1102176.5000 - val_loss: 1291608.0000\n",
      "Epoch 165/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1102073.5000 - val_loss: 1300529.8750\n",
      "Epoch 166/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1102679.3750 - val_loss: 1295525.7500\n",
      "Epoch 167/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1102200.2500 - val_loss: 1292284.1250\n",
      "Epoch 168/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1101989.3750 - val_loss: 1300666.5000\n",
      "Epoch 169/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1101060.8750 - val_loss: 1294579.2500\n",
      "Epoch 170/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1101469.8750 - val_loss: 1302533.3750\n",
      "Epoch 171/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1100071.0000 - val_loss: 1295254.3750\n",
      "Epoch 172/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1100296.0000 - val_loss: 1300073.7500\n",
      "Epoch 173/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1100504.1250 - val_loss: 1302618.3750\n",
      "Epoch 174/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1099908.7500 - val_loss: 1286051.1250\n",
      "Epoch 175/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1100668.8750 - val_loss: 1295371.5000\n",
      "Epoch 176/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1099901.0000 - val_loss: 1302578.7500\n",
      "Epoch 177/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1099505.1250 - val_loss: 1301689.6250\n",
      "Epoch 178/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1099155.2500 - val_loss: 1291020.3750\n",
      "Epoch 179/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1099000.3750 - val_loss: 1294662.6250\n",
      "Epoch 180/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1098546.6250 - val_loss: 1294202.8750\n",
      "Epoch 181/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1095355.1250 - val_loss: 1318440.7500\n",
      "Epoch 182/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1098827.2500 - val_loss: 1293548.3750\n",
      "Epoch 183/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1098231.5000 - val_loss: 1293440.2500\n",
      "Epoch 184/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1097930.3750 - val_loss: 1299295.7500\n",
      "Epoch 185/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1097203.0000 - val_loss: 1302429.7500\n",
      "Epoch 186/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1096347.6250 - val_loss: 1302543.2500\n",
      "Epoch 187/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1097497.1250 - val_loss: 1292746.0000\n",
      "Epoch 188/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1093241.1250 - val_loss: 1289079.3750\n",
      "Epoch 189/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1096024.5000 - val_loss: 1301169.7500\n",
      "Epoch 190/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1096622.1250 - val_loss: 1299112.3750\n",
      "Epoch 191/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1095294.2500 - val_loss: 1316897.0000\n",
      "Epoch 192/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1095291.3750 - val_loss: 1289834.2500\n",
      "Epoch 193/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1094340.3750 - val_loss: 1318841.7500\n",
      "Epoch 194/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1094988.8750 - val_loss: 1296408.0000\n",
      "Epoch 195/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1094889.0000 - val_loss: 1313800.7500\n",
      "Epoch 196/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1094496.3750 - val_loss: 1307951.5000\n",
      "Epoch 197/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1094511.2500 - val_loss: 1295536.3750\n",
      "Epoch 198/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1094371.5000 - val_loss: 1294087.1250\n",
      "Epoch 199/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1094268.7500 - val_loss: 1301411.0000\n",
      "Epoch 200/200\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1092967.1250 - val_loss: 1292117.2500\n",
      "40/40 [==============================] - 0s 801us/step\n"
     ]
    }
   ],
   "source": [
    "num_neurons = [21,10] # two hidden layers, first with 21 and second woth 10 neurons\n",
    "num_epochs = 200\n",
    "num_splits = 2\n",
    "test_size = 0.25\n",
    "\n",
    "R2_SCORES = []\n",
    "MAE = []\n",
    "LOSS = []\n",
    "VALIDATION_LOSS = []\n",
    "\n",
    "model = run_train_model(num_neurons, num_epochs, num_splits, test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01534004",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "The R2 score should end up at around 0.58-0.59 consistently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d7b366f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score: 0.60 [0.596741611124145, 0.5941313362019192]\n",
      "mae:  [778.7207813113379, 798.8059395651172]\n",
      "test loss: [1248869.5  1292117.25]\n"
     ]
    }
   ],
   "source": [
    "r2_avg = sum(R2_SCORES)/len(R2_SCORES)\n",
    "print(\"r2 score: %.2f\" % r2_avg, R2_SCORES)\n",
    "print(\"mae: \", MAE)\n",
    "print(\"test loss:\", np.array(VALIDATION_LOSS)[:,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c729e7",
   "metadata": {},
   "source": [
    "Plot learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "39c0ec7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(len(LOSS)):\n",
    "    plt.plot(LOSS[i])\n",
    "    plt.plot(VALIDATION_LOSS[i])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "37c82d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111/111 [==============================] - 0s 852us/step\n"
     ]
    }
   ],
   "source": [
    "# get predictions for the test data\n",
    "test_preds = model.predict(test_X_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0d9c7b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the predicted prices to file\n",
    "res1 = test_df[['Item_Identifier', 'Outlet_Identifier']]\n",
    "res2 = pd.DataFrame(test_preds)\n",
    "final_result = pd.concat([res1, res2], axis=1)\n",
    "final_result.rename(columns={'0':'Item_Outlet_Sales'}, inplace=True)\n",
    "final_result.to_csv('problem_3_predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
